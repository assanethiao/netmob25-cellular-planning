{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0152d03e-500e-48a3-b9dc-41285bcfc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_mobility_ns3/models/vae.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ConditionalTrajectoryVAE(nn.Module):\n",
    "    \"\"\"LSTM-based Conditional VAE for trajectory generation with transport mode and length conditioning.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 3,  # lat, lon, speed\n",
    "        sequence_length: int = 2000,\n",
    "        hidden_dim: int = 128,\n",
    "        latent_dim: int = 32,\n",
    "        num_layers: int = 2,\n",
    "        num_transport_modes: int = 5,  # number of transport modes\n",
    "        condition_dim: int = 32,  # dimension for condition embeddings\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.num_transport_modes = num_transport_modes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Condition embeddings\n",
    "        self.transport_mode_embedding = nn.Embedding(num_transport_modes, condition_dim)\n",
    "        self.length_projection = nn.Linear(1, condition_dim)\n",
    "        \n",
    "        # Total condition dimension (transport mode + length)\n",
    "        total_condition_dim = condition_dim * 2\n",
    "        \n",
    "        # Encoder - LSTM with bidirectional processing\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        encoder_output_dim = hidden_dim * 2  # bidirectional\n",
    "        \n",
    "        # Latent space projections (include conditions)\n",
    "        self.fc_mu = nn.Linear(encoder_output_dim + total_condition_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(encoder_output_dim + total_condition_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc_latent = nn.Linear(latent_dim + total_condition_dim, hidden_dim)\n",
    "        self.decoder_lstm = nn.LSTM(\n",
    "            hidden_dim, hidden_dim, num_layers, \n",
    "            batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                if len(param.shape) >= 2:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                else:\n",
    "                    nn.init.uniform_(param, -0.1, 0.1)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "    \n",
    "    def get_conditions(self, transport_mode: torch.Tensor, trip_length: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Create condition embeddings from transport mode and trip length.\"\"\"\n",
    "        # Transport mode embedding\n",
    "        mode_embed = self.transport_mode_embedding(transport_mode)  # (batch, condition_dim)\n",
    "        \n",
    "        # Length embedding (normalize length and project)\n",
    "        length_normalized = trip_length.unsqueeze(-1).float() / self.sequence_length  # normalize to [0,1]\n",
    "        length_embed = self.length_projection(length_normalized)  # (batch, condition_dim)\n",
    "        \n",
    "        # Concatenate conditions\n",
    "        conditions = torch.cat([mode_embed, length_embed], dim=-1)  # (batch, condition_dim * 2)\n",
    "        return conditions\n",
    "    \n",
    "    def encode(self, x: torch.Tensor, conditions: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encode trajectory to latent distribution parameters.\"\"\"\n",
    "        # LSTM encoding\n",
    "        _, (h, _) = self.encoder_lstm(x)\n",
    "        # Concatenate forward and backward hidden states from last layer\n",
    "        h = torch.cat([h[-2], h[-1]], dim=1)  # (batch, hidden_dim * 2)\n",
    "        h = self.dropout_layer(h)\n",
    "        \n",
    "        # Concatenate with conditions\n",
    "        h_conditioned = torch.cat([h, conditions], dim=-1)\n",
    "        \n",
    "        mu = self.fc_mu(h_conditioned)\n",
    "        logvar = self.fc_logvar(h_conditioned)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Reparameterization trick.\"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z: torch.Tensor, conditions: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode from latent space to trajectory.\"\"\"\n",
    "        batch_size = z.size(0)\n",
    "        \n",
    "        # Concatenate latent with conditions\n",
    "        z_conditioned = torch.cat([z, conditions], dim=-1)\n",
    "        \n",
    "        # Project to hidden and create sequence\n",
    "        h = self.fc_latent(z_conditioned)\n",
    "        h = torch.tanh(h)  # Add non-linearity\n",
    "        h = h.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        \n",
    "        # Decode sequence\n",
    "        out, _ = self.decoder_lstm(h)\n",
    "        out = self.dropout_layer(out)\n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        transport_mode: torch.Tensor, \n",
    "        trip_length: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor] = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        conditions = self.get_conditions(transport_mode, trip_length)\n",
    "        mu, logvar = self.encode(x, conditions)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z, conditions)\n",
    "        return recon, mu, logvar\n",
    "    \n",
    "    def generate(\n",
    "        self, \n",
    "        transport_mode: torch.Tensor, \n",
    "        trip_length: torch.Tensor, \n",
    "        n_samples: Optional[int] = None,\n",
    "        device: str = 'cpu'\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Generate new trajectories given conditions.\"\"\"\n",
    "        if n_samples is None:\n",
    "            n_samples = transport_mode.size(0)\n",
    "            \n",
    "        conditions = self.get_conditions(transport_mode, trip_length)\n",
    "        z = torch.randn(n_samples, self.latent_dim).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            trajectories = self.decode(z, conditions)\n",
    "        return trajectories\n",
    "    \n",
    "    def get_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get model configuration.\"\"\"\n",
    "        return {\n",
    "            'input_dim': self.input_dim,\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'num_layers': self.num_layers,\n",
    "            'num_transport_modes': self.num_transport_modes,\n",
    "            'condition_dim': self.condition_dim,\n",
    "            'dropout': self.dropout,\n",
    "        }\n",
    "\n",
    "\n",
    "def masked_vae_loss(\n",
    "    recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    mu: torch.Tensor, \n",
    "    logvar: torch.Tensor, \n",
    "    mask: torch.Tensor,\n",
    "    beta: float = 1.0\n",
    ") -> Tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    VAE loss function with masking for variable-length sequences.\n",
    "    \n",
    "    Args:\n",
    "        recon: Reconstructed trajectories (batch, seq_len, input_dim)\n",
    "        x: Original trajectories (batch, seq_len, input_dim)\n",
    "        mu: Latent mean (batch, latent_dim)\n",
    "        logvar: Latent log variance (batch, latent_dim)\n",
    "        mask: Binary mask indicating valid positions (batch, seq_len)\n",
    "        beta: Weight for KL loss\n",
    "    \"\"\"\n",
    "    # Reconstruction loss with masking (MSE)\n",
    "    diff = (recon - x) ** 2  # (batch, seq_len, input_dim)\n",
    "    \n",
    "    # Expand mask to match input dimensions\n",
    "    mask_expanded = mask.unsqueeze(-1).expand_as(diff)  # (batch, seq_len, input_dim)\n",
    "    \n",
    "    # Apply mask and compute mean over valid positions\n",
    "    masked_diff = diff * mask_expanded\n",
    "    num_valid = mask_expanded.sum()\n",
    "    recon_loss = masked_diff.sum() / (num_valid + 1e-8)  # avoid division by zero\n",
    "    \n",
    "    # KL divergence (not masked, applied to latent space)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.size(0)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = recon_loss + beta * kl_loss\n",
    "    \n",
    "    return loss, {\n",
    "        'loss': loss.item(),\n",
    "        'recon_loss': recon_loss.item(),\n",
    "        'kl_loss': kl_loss.item(),\n",
    "        'num_valid_points': num_valid.item()\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_trajectory_metrics(pred: torch.Tensor, target: torch.Tensor, mask: torch.Tensor) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute trajectory-specific metrics.\n",
    "    \n",
    "    Args:\n",
    "        pred: Predicted trajectories (batch, seq_len, 3) [lat, lon, speed]\n",
    "        target: Target trajectories (batch, seq_len, 3) [lat, lon, speed]\n",
    "        mask: Binary mask (batch, seq_len)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    # Apply mask\n",
    "    mask_expanded = mask.unsqueeze(-1)\n",
    "    pred_masked = pred * mask_expanded\n",
    "    target_masked = target * mask_expanded\n",
    "    \n",
    "    # Speed MAE\n",
    "    speed_mae = torch.abs(pred_masked[:, :, 2] - target_masked[:, :, 2])\n",
    "    speed_mae = (speed_mae * mask).sum() / (mask.sum() + 1e-8)\n",
    "    \n",
    "    # Distance metrics (using lat, lon)\n",
    "    def compute_distances(traj):\n",
    "        \"\"\"Compute total and bird distances for a trajectory.\"\"\"\n",
    "        # Total distance (sum of segments)\n",
    "        lat_diff = torch.diff(traj[:, :, 0], dim=1)\n",
    "        lon_diff = torch.diff(traj[:, :, 1], dim=1)\n",
    "        segment_distances = torch.sqrt(lat_diff**2 + lon_diff**2) * 111  # rough km conversion\n",
    "        total_distance = segment_distances.sum(dim=1)\n",
    "        \n",
    "        # Bird distance (start to end)\n",
    "        valid_lengths = mask.sum(dim=1)\n",
    "        bird_distances = []\n",
    "        for i, length in enumerate(valid_lengths):\n",
    "            if length > 1:\n",
    "                start = traj[i, 0, :2]\n",
    "                end = traj[i, length-1, :2]\n",
    "                bird_dist = torch.sqrt(((end - start)**2).sum()) * 111\n",
    "                bird_distances.append(bird_dist)\n",
    "            else:\n",
    "                bird_distances.append(torch.tensor(0.0, device=traj.device))\n",
    "        \n",
    "        return total_distance, torch.stack(bird_distances)\n",
    "    \n",
    "    pred_total_dist, pred_bird_dist = compute_distances(pred_masked)\n",
    "    target_total_dist, target_bird_dist = compute_distances(target_masked)\n",
    "    \n",
    "    # Distance MAEs\n",
    "    total_dist_mae = torch.abs(pred_total_dist - target_total_dist).mean()\n",
    "    bird_dist_mae = torch.abs(pred_bird_dist - target_bird_dist).mean()\n",
    "    \n",
    "    return {\n",
    "        'speed_mae': speed_mae.item(),\n",
    "        'total_distance_mae': total_dist_mae.item(),\n",
    "        'bird_distance_mae': bird_dist_mae.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e763e95f-6aa0-441d-882c-e2c64a168ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_mobility_ns3.models.vae'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Add project to path\u001b[39;00m\n\u001b[32m      9\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../..\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_mobility_ns3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvae\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConditionalTrajectoryVAE\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device\u001b[39m():\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the best available device.\"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ml_mobility_ns3.models.vae'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "from ml_mobility_ns3.models.vae import ConditionalTrajectoryVAE\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_simple(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    duration_minutes: float,\n",
    "    n_samples: int = 10,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate trajectories with specified parameters.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    # Convert duration to steps (2 seconds per step)\n",
    "    trip_length = int(duration_minutes * 60 / 2)\n",
    "    trip_length = min(trip_length, 2000)  # Cap at model max\n",
    "    \n",
    "    # Create tensors\n",
    "    mode_tensor = torch.full((n_samples,), mode_idx, dtype=torch.long).to(device)\n",
    "    length_tensor = torch.full((n_samples,), trip_length, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "    \n",
    "    return trajectories.cpu().numpy(), trip_length\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\n",
    "    \n",
    "    Args:\n",
    "        trajectories: numpy array of shape (n_samples, seq_len, n_features)\n",
    "        scaler: Either a sklearn scaler object or a dict containing scalers\n",
    "    \"\"\"\n",
    "    # Handle both scaler object and dict cases\n",
    "    if isinstance(scaler, dict):\n",
    "        # Extract the trajectory scaler from the dict\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    n_samples, seq_len, n_features = trajectories.shape\n",
    "    traj_flat = trajectories.reshape(-1, n_features)\n",
    "    traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "    return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_basic_stats(trajectories, trip_length):\n",
    "    \"\"\"Compute basic statistics for generated trajectories.\"\"\"\n",
    "    stats = []\n",
    "    \n",
    "    for i, traj in enumerate(trajectories):\n",
    "        # Only look at valid portion\n",
    "        valid_traj = traj[:trip_length]\n",
    "        \n",
    "        # Speed stats (assuming index 2 is speed in m/s)\n",
    "        speeds_ms = valid_traj[:, 2]\n",
    "        speeds_kmh = speeds_ms * 3.6\n",
    "        \n",
    "        # Distance calculation\n",
    "        if trip_length > 1:\n",
    "            lat_diff = np.diff(valid_traj[:, 0])\n",
    "            lon_diff = np.diff(valid_traj[:, 1])\n",
    "            # Approximate distance in km\n",
    "            distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111\n",
    "            total_distance = distances.sum()\n",
    "            \n",
    "            # Bird distance\n",
    "            start = valid_traj[0, :2]\n",
    "            end = valid_traj[trip_length-1, :2]\n",
    "            bird_distance = np.sqrt(((end - start)**2).sum()) * 111\n",
    "        else:\n",
    "            total_distance = 0\n",
    "            bird_distance = 0\n",
    "        \n",
    "        stats.append({\n",
    "            'trajectory_id': i,\n",
    "            'mean_speed_kmh': speeds_kmh.mean(),\n",
    "            'max_speed_kmh': speeds_kmh.max(),\n",
    "            'total_distance_km': total_distance,\n",
    "            'bird_distance_km': bird_distance,\n",
    "            'duration_min': trip_length * 2 / 60\n",
    "        })\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Main usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed \")\n",
    "    \n",
    "    # Get device\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "    # Load scalers (this returns a dict)\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    print(f\"Loaded scalers: {list(scalers.keys())}\")\n",
    "    \n",
    "    # Generate trajectories\n",
    "    transport_mode = \"CAR\"\n",
    "    duration_minutes = 20.0\n",
    "    n_samples = 5\n",
    "    \n",
    "    print(f\"\\nGenerating {n_samples} {transport_mode} trajectories of {duration_minutes} minutes...\")\n",
    "    trajectories_norm, trip_length = generate_simple(\n",
    "        model, \n",
    "        transport_mode, \n",
    "        duration_minutes, \n",
    "        n_samples, \n",
    "        device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units - pass the scalers dict (or just the trajectory scaler)\n",
    "    print(\"Converting to real units...\")\n",
    "    trajectories_real = inverse_transform_simple(trajectories_norm, scalers)\n",
    "    # Or alternatively: trajectories_real = inverse_transform_simple(trajectories_norm, scalers['trajectory'])\n",
    "    \n",
    "    # Compute stats\n",
    "    print(\"\\nComputing statistics...\")\n",
    "    stats = compute_basic_stats(trajectories_real, trip_length)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nGenerated {n_samples} trajectories:\")\n",
    "    print(f\"Trip length: {trip_length} steps ({duration_minutes} minutes)\")\n",
    "    print(\"\\nTrajectory Statistics:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'ID':>3} | {'Mean Speed':>10} | {'Max Speed':>10} | {'Total Dist':>10} | {'Bird Dist':>10}\")\n",
    "    print(f\"{'':>3} | {'(km/h)':>10} | {'(km/h)':>10} | {'(km)':>10} | {'(km)':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for stat in stats:\n",
    "        print(f\"{stat['trajectory_id']:>3} | \"\n",
    "              f\"{stat['mean_speed_kmh']:>10.1f} | \"\n",
    "              f\"{stat['max_speed_kmh']:>10.1f} | \"\n",
    "              f\"{stat['total_distance_km']:>10.2f} | \"\n",
    "              f\"{stat['bird_distance_km']:>10.2f}\")\n",
    "    \n",
    "    # Average stats\n",
    "    mean_speed = np.mean([s['mean_speed_kmh'] for s in stats])\n",
    "    mean_total_dist = np.mean([s['total_distance_km'] for s in stats])\n",
    "    mean_bird_dist = np.mean([s['bird_distance_km'] for s in stats])\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Average: {mean_speed:>19.1f} | {'':>10} | {mean_total_dist:>10.2f} | {mean_bird_dist:>10.2f}\")\n",
    "    \n",
    "    # Save one trajectory example\n",
    "    print(f\"\\nFirst trajectory sample (first 5 points):\")\n",
    "    print(\"Lat, Lon, Speed (m/s)\")\n",
    "    for i in range(min(5, trip_length)):\n",
    "        point = trajectories_real[0, i]\n",
    "        print(f\"{point[0]:.6f}, {point[1]:.6f}, {point[2]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b20728c-db4d-46f7-ad0c-da936b351560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Loading model...\n",
      "Loading scalers...\n",
      "\n",
      "================================================================================\n",
      "Processing CAR\n",
      "================================================================================\n",
      "Found 25169 CAR trajectories\n",
      "\n",
      "Generating 25169 CAR trajectories...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 543\u001b[39m\n\u001b[32m    540\u001b[39m preprocessing_dir = Path(\u001b[33m\"\u001b[39m\u001b[33m../data/processed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    542\u001b[39m \u001b[38;5;66;03m# Run complete analysis for ALL trajectories\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m summary_df, results = \u001b[43mrun_complete_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreprocessing_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreprocessing_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport_modes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCAR\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWALKING\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMIXED\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBIKE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUBLIC_TRANSPORT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Process in batches for efficiency\u001b[39;49;00m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_sample_maps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save sample visualizations\u001b[39;49;00m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of trajectories to show in sample maps\u001b[39;49;00m\n\u001b[32m    550\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 461\u001b[39m, in \u001b[36mrun_complete_analysis\u001b[39m\u001b[34m(checkpoint_dir, preprocessing_dir, transport_modes, batch_size, save_sample_maps, sample_size)\u001b[39m\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;66;03m# Generate matched trajectories for ALL real ones\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m generated_trajectories = \u001b[43mgenerate_all_matched_trajectories\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_trajectories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# Compute aggregate statistics\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mComputing statistics...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 207\u001b[39m, in \u001b[36mgenerate_all_matched_trajectories\u001b[39m\u001b[34m(model, scalers, real_trajectories, transport_mode, device, batch_size)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trip_lengths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransport_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m trajectories...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Generate in batches\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m gen_trajectories_norm = \u001b[43mgenerate_batch_trajectories\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransport_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrip_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# Convert to real units\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConverting to real units...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mgenerate_batch_trajectories\u001b[39m\u001b[34m(model, transport_mode, trip_lengths, batch_size, device)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;66;03m# Generate\u001b[39;00m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m         batch_trajectories = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     all_trajectories.append(batch_trajectories.cpu().numpy())\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Concatenate all batches\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 159\u001b[39m, in \u001b[36mConditionalTrajectoryVAE.generate\u001b[39m\u001b[34m(self, transport_mode, trip_length, n_samples, device)\u001b[39m\n\u001b[32m    156\u001b[39m z = torch.randn(n_samples, \u001b[38;5;28mself\u001b[39m.latent_dim).to(device)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     trajectories = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trajectories\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mConditionalTrajectoryVAE.decode\u001b[39m\u001b[34m(self, z, conditions)\u001b[39m\n\u001b[32m    121\u001b[39m h = h.unsqueeze(\u001b[32m1\u001b[39m).repeat(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.sequence_length, \u001b[32m1\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Decode sequence\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m out = \u001b[38;5;28mself\u001b[39m.dropout_layer(out)\n\u001b[32m    126\u001b[39m out = \u001b[38;5;28mself\u001b[39m.fc_out(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/ml-mobility-ns3-nuqJhA4m-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/ml-mobility-ns3-nuqJhA4m-py3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/ml-mobility-ns3-nuqJhA4m-py3.13/lib/python3.13/site-packages/torch/nn/modules/rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import folium\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Import generation functions from the fixed script\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_batch_trajectories(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    trip_lengths: List[int],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate multiple trajectories in batches for efficiency.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    all_trajectories = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(trip_lengths), batch_size):\n",
    "        batch_lengths = trip_lengths[i:i+batch_size]\n",
    "        batch_size_actual = len(batch_lengths)\n",
    "        \n",
    "        # Cap lengths at model max\n",
    "        batch_lengths = [min(l, 2000) for l in batch_lengths]\n",
    "        \n",
    "        # Create tensors\n",
    "        mode_tensor = torch.full((batch_size_actual,), mode_idx, dtype=torch.long).to(device)\n",
    "        length_tensor = torch.tensor(batch_lengths, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            batch_trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "        \n",
    "        all_trajectories.append(batch_trajectories.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    return np.vstack(all_trajectories) if all_trajectories else np.array([])\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\"\"\"\n",
    "    if isinstance(scaler, dict):\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    if len(trajectories.shape) == 2:\n",
    "        # Single trajectory\n",
    "        return trajectory_scaler.inverse_transform(trajectories)\n",
    "    else:\n",
    "        # Multiple trajectories\n",
    "        n_samples, seq_len, n_features = trajectories.shape\n",
    "        traj_flat = trajectories.reshape(-1, n_features)\n",
    "        traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "        return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_trajectory_metrics(trajectory: np.ndarray, valid_length: Optional[int] = None) -> Dict:\n",
    "    \"\"\"Compute metrics for a single trajectory.\"\"\"\n",
    "    if valid_length is None:\n",
    "        # Find valid length by checking for zero padding\n",
    "        valid_mask = ~np.all(trajectory == 0, axis=1)\n",
    "        valid_length = np.sum(valid_mask)\n",
    "    \n",
    "    # Get valid portion\n",
    "    valid_traj = trajectory[:valid_length]\n",
    "    \n",
    "    # Duration in minutes (2 seconds per point)\n",
    "    duration_min = valid_length * 2 / 60\n",
    "    \n",
    "    # Speed statistics\n",
    "    speeds_ms = valid_traj[:, 2]\n",
    "    speeds_kmh = speeds_ms * 3.6\n",
    "    avg_speed = np.mean(speeds_kmh)\n",
    "    std_speed = np.std(speeds_kmh)\n",
    "    max_speed = np.max(speeds_kmh)\n",
    "    \n",
    "    # Distance calculations\n",
    "    if valid_length > 1:\n",
    "        lat_diff = np.diff(valid_traj[:, 0])\n",
    "        lon_diff = np.diff(valid_traj[:, 1])\n",
    "        distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111  # Approximate km\n",
    "        total_distance = np.sum(distances)\n",
    "        \n",
    "        # Bird distance\n",
    "        start = valid_traj[0, :2]\n",
    "        end = valid_traj[-1, :2]\n",
    "        bird_distance = np.sqrt(np.sum((end - start)**2)) * 111\n",
    "    else:\n",
    "        total_distance = 0\n",
    "        bird_distance = 0\n",
    "    \n",
    "    return {\n",
    "        'duration_min': duration_min,\n",
    "        'avg_speed_kmh': avg_speed,\n",
    "        'std_speed_kmh': std_speed,\n",
    "        'max_speed_kmh': max_speed,\n",
    "        'total_distance_km': total_distance,\n",
    "        'bird_distance_km': bird_distance,\n",
    "        'valid_points': valid_length\n",
    "    }\n",
    "\n",
    "def load_all_real_trajectories(preprocessing_dir: Path, transport_mode: str):\n",
    "    \"\"\"Load ALL real trajectories for a transport mode.\"\"\"\n",
    "    # Load interpolated trips\n",
    "    with open(preprocessing_dir / 'interpolated_trips.pkl', 'rb') as f:\n",
    "        interpolated_trips = pickle.load(f)\n",
    "    \n",
    "    # Filter by transport mode\n",
    "    mode_trips = [t for t in interpolated_trips if t['category'] == transport_mode]\n",
    "    \n",
    "    if len(mode_trips) == 0:\n",
    "        print(f\"No trips found for mode: {transport_mode}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(mode_trips)} {transport_mode} trajectories\")\n",
    "    \n",
    "    # Convert all trips\n",
    "    real_trajectories = []\n",
    "    for trip in mode_trips:\n",
    "        # GPS points: [timestamp, lat, lon, speed]\n",
    "        gps_points = trip['gps_points']\n",
    "        # Extract lat, lon, speed\n",
    "        trajectory = gps_points[:, 1:4].astype(np.float32)\n",
    "        \n",
    "        real_trajectories.append({\n",
    "            'trajectory': trajectory,\n",
    "            'trip_id': trip['trip_id'],\n",
    "            'user_id': trip['user_id'],\n",
    "            'category': trip['category'],\n",
    "            'trip_type': trip['trip_type'],\n",
    "            'original_duration': trip['duration_minutes'],\n",
    "            'length': len(trajectory),\n",
    "            'weight': trip.get('weight', 1.0)\n",
    "        })\n",
    "    \n",
    "    return real_trajectories\n",
    "\n",
    "def generate_all_matched_trajectories(\n",
    "    model,\n",
    "    scalers,\n",
    "    real_trajectories: List[Dict],\n",
    "    transport_mode: str,\n",
    "    device: str,\n",
    "    batch_size: int = 32\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Generate trajectories matching all real trajectories' lengths.\"\"\"\n",
    "    \n",
    "    # Extract lengths\n",
    "    trip_lengths = [t['length'] for t in real_trajectories]\n",
    "    \n",
    "    print(f\"\\nGenerating {len(trip_lengths)} {transport_mode} trajectories...\")\n",
    "    \n",
    "    # Generate in batches\n",
    "    gen_trajectories_norm = generate_batch_trajectories(\n",
    "        model, transport_mode, trip_lengths, batch_size, device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units\n",
    "    print(\"Converting to real units...\")\n",
    "    gen_trajectories_real = inverse_transform_simple(gen_trajectories_norm, scalers)\n",
    "    \n",
    "    # Create trajectory info list\n",
    "    generated_trajectories = []\n",
    "    for i, (gen_traj, real_info) in enumerate(zip(gen_trajectories_real, real_trajectories)):\n",
    "        generated_trajectories.append({\n",
    "            'trajectory': gen_traj,\n",
    "            'matched_to': real_info['trip_id'],\n",
    "            'category': transport_mode,\n",
    "            'length': real_info['length'],\n",
    "            'weight': real_info['weight']\n",
    "        })\n",
    "    \n",
    "    return generated_trajectories\n",
    "\n",
    "def compute_aggregate_statistics(trajectories: List[Dict], label: str = \"\") -> Dict:\n",
    "    \"\"\"Compute aggregate statistics for a set of trajectories.\"\"\"\n",
    "    all_metrics = []\n",
    "    total_weight = 0\n",
    "    \n",
    "    for traj_info in trajectories:\n",
    "        metrics = compute_trajectory_metrics(\n",
    "            traj_info['trajectory'], \n",
    "            traj_info.get('length')\n",
    "        )\n",
    "        metrics['weight'] = traj_info.get('weight', 1.0)\n",
    "        all_metrics.append(metrics)\n",
    "        total_weight += metrics['weight']\n",
    "    \n",
    "    # Extract arrays for each metric\n",
    "    durations = np.array([m['duration_min'] for m in all_metrics])\n",
    "    avg_speeds = np.array([m['avg_speed_kmh'] for m in all_metrics])\n",
    "    bird_distances = np.array([m['bird_distance_km'] for m in all_metrics])\n",
    "    total_distances = np.array([m['total_distance_km'] for m in all_metrics])\n",
    "    weights = np.array([m['weight'] for m in all_metrics])\n",
    "    \n",
    "    # Compute weighted statistics\n",
    "    def weighted_mean(values, weights):\n",
    "        return np.sum(values * weights) / np.sum(weights)\n",
    "    \n",
    "    def weighted_std(values, weights):\n",
    "        mean = weighted_mean(values, weights)\n",
    "        variance = weighted_mean((values - mean)**2, weights)\n",
    "        return np.sqrt(variance)\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'n_trajectories': len(trajectories),\n",
    "        'total_weight': total_weight,\n",
    "        'duration_mean': weighted_mean(durations, weights),\n",
    "        'duration_std': weighted_std(durations, weights),\n",
    "        'duration_min': np.min(durations),\n",
    "        'duration_max': np.max(durations),\n",
    "        'speed_mean': weighted_mean(avg_speeds, weights),\n",
    "        'speed_std': weighted_std(avg_speeds, weights),\n",
    "        'speed_min': np.min(avg_speeds),\n",
    "        'speed_max': np.max(avg_speeds),\n",
    "        'bird_distance_mean': weighted_mean(bird_distances, weights),\n",
    "        'bird_distance_std': weighted_std(bird_distances, weights),\n",
    "        'bird_distance_min': np.min(bird_distances),\n",
    "        'bird_distance_max': np.max(bird_distances),\n",
    "        'total_distance_mean': weighted_mean(total_distances, weights),\n",
    "        'total_distance_std': weighted_std(total_distances, weights),\n",
    "        'total_distance_min': np.min(total_distances),\n",
    "        'total_distance_max': np.max(total_distances),\n",
    "    }\n",
    "\n",
    "def print_mode_comparison(mode: str, real_stats: Dict, gen_stats: Dict):\n",
    "    \"\"\"Print detailed comparison for a transport mode.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{mode} COMPARISON\")\n",
    "    print('='*80)\n",
    "    \n",
    "    print(f\"\\nDataset size:\")\n",
    "    print(f\"  Real trajectories: {real_stats['n_trajectories']:,} (weight: {real_stats['total_weight']:,.0f})\")\n",
    "    print(f\"  Generated trajectories: {gen_stats['n_trajectories']:,} (weight: {gen_stats['total_weight']:,.0f})\")\n",
    "    \n",
    "    metrics = [\n",
    "        ('Duration (min)', 'duration'),\n",
    "        ('Speed avg (km/h)', 'speed'),\n",
    "        ('Bird distance (km)', 'bird_distance'),\n",
    "        ('Total distance (km)', 'total_distance')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nMetric comparison (weighted statistics):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric_name, metric_key in metrics:\n",
    "        real_mean = real_stats[f'{metric_key}_mean']\n",
    "        real_std = real_stats[f'{metric_key}_std']\n",
    "        gen_mean = gen_stats[f'{metric_key}_mean']\n",
    "        gen_std = gen_stats[f'{metric_key}_std']\n",
    "        \n",
    "        # Calculate relative error\n",
    "        rel_error = abs(gen_mean - real_mean) / real_mean * 100 if real_mean > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Real:      {real_mean:.2f}  {real_std:.2f} (range: [{real_stats[f'{metric_key}_min']:.2f}, {real_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Generated: {gen_mean:.2f}  {gen_std:.2f} (range: [{gen_stats[f'{metric_key}_min']:.2f}, {gen_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Relative Error: {rel_error:.1f}%\")\n",
    "\n",
    "def create_sample_visualization_map(\n",
    "    real_trajectories: List[Dict],\n",
    "    generated_trajectories: List[Dict],\n",
    "    mode: str,\n",
    "    n_samples: int = 10,\n",
    "    output_file: str = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"Create a map with a sample of trajectories for visualization.\"\"\"\n",
    "    # Sample trajectories if needed\n",
    "    if len(real_trajectories) > n_samples:\n",
    "        sample_indices = np.random.choice(len(real_trajectories), n_samples, replace=False)\n",
    "        real_sample = [real_trajectories[i] for i in sample_indices]\n",
    "        gen_sample = [generated_trajectories[i] for i in sample_indices]\n",
    "    else:\n",
    "        real_sample = real_trajectories\n",
    "        gen_sample = generated_trajectories\n",
    "    \n",
    "    # Prepare for visualization\n",
    "    all_trajectories = []\n",
    "    labels = []\n",
    "    types = []\n",
    "    \n",
    "    for i, traj_info in enumerate(real_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Real {mode} {i+1}\")\n",
    "        types.append('real')\n",
    "    \n",
    "    for i, traj_info in enumerate(gen_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Generated {mode} {i+1}\")\n",
    "        types.append('generated')\n",
    "    \n",
    "    # Calculate center\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    for traj in all_trajectories:\n",
    "        valid_mask = ~np.all(traj == 0, axis=1)\n",
    "        all_lats.extend(traj[valid_mask, 0])\n",
    "        all_lons.extend(traj[valid_mask, 1])\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=11)\n",
    "    \n",
    "    # Define colors\n",
    "    real_colors = ['blue', 'darkblue', 'lightblue', 'navy', 'steelblue']\n",
    "    generated_colors = ['red', 'darkred', 'orange', 'pink', 'coral']\n",
    "    \n",
    "    # Add trajectories\n",
    "    for i, (traj, label, traj_type) in enumerate(zip(all_trajectories, labels, types)):\n",
    "        if traj_type == 'real':\n",
    "            color = real_colors[i % len(real_colors)]\n",
    "            line_style = None\n",
    "        else:\n",
    "            color = generated_colors[(i - len(real_sample)) % len(generated_colors)]\n",
    "            line_style = '10'\n",
    "        \n",
    "        # Get valid points\n",
    "        if traj_type == 'generated':\n",
    "            traj_info = gen_sample[i - len(real_sample)]\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "        else:\n",
    "            valid_mask = ~np.all(traj == 0, axis=1)\n",
    "            valid_traj = traj[valid_mask]\n",
    "        \n",
    "        points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "        \n",
    "        # Add polyline\n",
    "        if line_style:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.7,\n",
    "                dash_array=line_style,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "        else:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.8,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 50px; right: 50px; width: 250px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <p style=\"margin: 0;\"><b>{mode} Trajectories</b></p>\n",
    "    <p style=\"margin: 5px 0;\">Sample size: {len(real_sample)} of {len(real_trajectories)} total</p>\n",
    "    <p style=\"margin: 10px 0 5px 0;\"><b>Line styles:</b></p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: blue;\"></span> Real trajectories</p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: red;\"></span> Generated trajectories</p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    if output_file:\n",
    "        m.save(output_file)\n",
    "        print(f\"Sample visualization saved to: {output_file}\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def run_complete_analysis(\n",
    "    checkpoint_dir: Path,\n",
    "    preprocessing_dir: Path,\n",
    "    transport_modes: List[str] = [\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "    batch_size: int = 32,\n",
    "    save_sample_maps: bool = True,\n",
    "    sample_size: int = 10\n",
    "):\n",
    "    \"\"\"Run complete analysis generating trajectories for ALL real trajectories.\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    \n",
    "    # Load scalers\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    \n",
    "    # Storage for results\n",
    "    all_results = []\n",
    "    \n",
    "    # Process each transport mode\n",
    "    for mode in transport_modes:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {mode}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        # Load ALL real trajectories for this mode\n",
    "        real_trajectories = load_all_real_trajectories(preprocessing_dir, mode)\n",
    "        \n",
    "        if len(real_trajectories) == 0:\n",
    "            print(f\"Skipping {mode} - no trajectories found\")\n",
    "            continue\n",
    "        \n",
    "        # Generate matched trajectories for ALL real ones\n",
    "        generated_trajectories = generate_all_matched_trajectories(\n",
    "            model, scalers, real_trajectories, mode, device, batch_size\n",
    "        )\n",
    "        \n",
    "        # Compute aggregate statistics\n",
    "        print(\"\\nComputing statistics...\")\n",
    "        real_stats = compute_aggregate_statistics(real_trajectories, f\"Real {mode}\")\n",
    "        gen_stats = compute_aggregate_statistics(generated_trajectories, f\"Generated {mode}\")\n",
    "        \n",
    "        # Print comparison\n",
    "        print_mode_comparison(mode, real_stats, gen_stats)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mode': mode,\n",
    "            'real_stats': real_stats,\n",
    "            'gen_stats': gen_stats,\n",
    "            'n_trajectories': len(real_trajectories)\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Create sample visualization if requested\n",
    "        if save_sample_maps:\n",
    "            create_sample_visualization_map(\n",
    "                real_trajectories,\n",
    "                generated_trajectories,\n",
    "                mode,\n",
    "                n_samples=sample_size,\n",
    "                output_file=f\"{mode.lower()}_sample_trajectories.html\"\n",
    "            )\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY ACROSS ALL MODES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in all_results:\n",
    "        mode = result['mode']\n",
    "        real_stats = result['real_stats']\n",
    "        gen_stats = result['gen_stats']\n",
    "        \n",
    "        for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "            summary_data.append({\n",
    "                'transport_mode': mode,\n",
    "                'metric': metric,\n",
    "                'real_mean': real_stats[f'{metric}_mean'],\n",
    "                'real_std': real_stats[f'{metric}_std'],\n",
    "                'generated_mean': gen_stats[f'{metric}_mean'],\n",
    "                'generated_std': gen_stats[f'{metric}_std'],\n",
    "                'n_samples': result['n_trajectories'],\n",
    "                'relative_error': abs(gen_stats[f'{metric}_mean'] - real_stats[f'{metric}_mean']) / real_stats[f'{metric}_mean'] * 100 if real_stats[f'{metric}_mean'] > 0 else 0\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('all_trajectories_comparison.csv', index=False)\n",
    "    print(f\"\\nComplete comparison saved to: all_trajectories_comparison.csv\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nOverall Performance Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    metric_names = {\n",
    "        'duration': 'Duration (min)',\n",
    "        'speed': 'Speed (km/h)',\n",
    "        'bird_distance': 'Bird Distance (km)',\n",
    "        'total_distance': 'Total Distance (km)'\n",
    "    }\n",
    "    \n",
    "    for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "        metric_data = summary_df[summary_df['metric'] == metric]\n",
    "        avg_error = metric_data['relative_error'].mean()\n",
    "        print(f\"{metric_names[metric]}: Average relative error = {avg_error:.1f}%\")\n",
    "    \n",
    "    return summary_df, all_results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed\")\n",
    "    \n",
    "    # Run complete analysis for ALL trajectories\n",
    "    summary_df, results = run_complete_analysis(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        preprocessing_dir=preprocessing_dir,\n",
    "        transport_modes=[\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "        batch_size=32,  # Process in batches for efficiency\n",
    "        save_sample_maps=True,  # Save sample visualizations\n",
    "        sample_size=10  # Number of trajectories to show in sample maps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a02bcf-f42c-4b55-b8e2-89d176b603e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67501a-0671-4e0e-bc03-bb2264cee5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Loading model...\n",
      "Loading scalers...\n",
      "\n",
      "================================================================================\n",
      "Processing CAR\n",
      "================================================================================\n",
      "Found 25169 CAR trajectories\n",
      "\n",
      "Generating 25169 CAR trajectories...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import folium\n",
    "from typing import List, Union, Optional, Tuple, Dict\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../..')\n",
    "\n",
    "# Import generation functions from the fixed script\n",
    "def get_device():\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return 'cpu'  # Use CPU on Mac to avoid MPS issues\n",
    "    else:\n",
    "        return 'cpu'\n",
    "\n",
    "def load_model_simple(checkpoint_dir: Path, device: str = None):\n",
    "    \"\"\"Simply load the model without complications.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Load config\n",
    "    with open(checkpoint_dir / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Create model\n",
    "    model_config = config['model_config']\n",
    "    model = ConditionalTrajectoryVAE(**model_config)\n",
    "    \n",
    "    # Load weights - force CPU first to avoid device issues\n",
    "    checkpoint = torch.load(checkpoint_dir / 'best_model.pt', map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Then move to desired device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "def generate_batch_trajectories(\n",
    "    model, \n",
    "    transport_mode: str, \n",
    "    trip_lengths: List[int],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None\n",
    "):\n",
    "    \"\"\"Generate multiple trajectories in batches for efficiency.\"\"\"\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    \n",
    "    # Transport modes\n",
    "    modes = ['BIKE', 'CAR', 'MIXED', 'PUBLIC_TRANSPORT', 'WALKING']\n",
    "    mode_idx = modes.index(transport_mode)\n",
    "    \n",
    "    all_trajectories = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(trip_lengths), batch_size):\n",
    "        batch_lengths = trip_lengths[i:i+batch_size]\n",
    "        batch_size_actual = len(batch_lengths)\n",
    "        \n",
    "        # Cap lengths at model max\n",
    "        batch_lengths = [min(l, 2000) for l in batch_lengths]\n",
    "        \n",
    "        # Create tensors\n",
    "        mode_tensor = torch.full((batch_size_actual,), mode_idx, dtype=torch.long).to(device)\n",
    "        length_tensor = torch.tensor(batch_lengths, dtype=torch.long).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            batch_trajectories = model.generate(mode_tensor, length_tensor, device=device)\n",
    "        \n",
    "        all_trajectories.append(batch_trajectories.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    return np.vstack(all_trajectories) if all_trajectories else np.array([])\n",
    "\n",
    "def load_scaler_simple(preprocessing_dir: Path):\n",
    "    \"\"\"Load the scalers dictionary.\"\"\"\n",
    "    scaler_path = preprocessing_dir / 'scalers.pkl'\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def inverse_transform_simple(trajectories, scaler):\n",
    "    \"\"\"Convert from normalized to real units.\"\"\"\n",
    "    if isinstance(scaler, dict):\n",
    "        trajectory_scaler = scaler['trajectory']\n",
    "    else:\n",
    "        trajectory_scaler = scaler\n",
    "    \n",
    "    if len(trajectories.shape) == 2:\n",
    "        # Single trajectory\n",
    "        return trajectory_scaler.inverse_transform(trajectories)\n",
    "    else:\n",
    "        # Multiple trajectories\n",
    "        n_samples, seq_len, n_features = trajectories.shape\n",
    "        traj_flat = trajectories.reshape(-1, n_features)\n",
    "        traj_real = trajectory_scaler.inverse_transform(traj_flat)\n",
    "        return traj_real.reshape(n_samples, seq_len, n_features)\n",
    "\n",
    "def compute_trajectory_metrics(trajectory: np.ndarray, valid_length: Optional[int] = None) -> Dict:\n",
    "    \"\"\"Compute metrics for a single trajectory.\"\"\"\n",
    "    if valid_length is None:\n",
    "        # Find valid length by checking for zero padding\n",
    "        valid_mask = ~np.all(trajectory == 0, axis=1)\n",
    "        valid_length = np.sum(valid_mask)\n",
    "    \n",
    "    # Get valid portion\n",
    "    valid_traj = trajectory[:valid_length]\n",
    "    \n",
    "    # Duration in minutes (2 seconds per point)\n",
    "    duration_min = valid_length * 2 / 60\n",
    "    \n",
    "    # Speed statistics\n",
    "    speeds_ms = valid_traj[:, 2]\n",
    "    speeds_kmh = speeds_ms * 3.6\n",
    "    avg_speed = np.mean(speeds_kmh)\n",
    "    std_speed = np.std(speeds_kmh)\n",
    "    max_speed = np.max(speeds_kmh)\n",
    "    \n",
    "    # Distance calculations\n",
    "    if valid_length > 1:\n",
    "        lat_diff = np.diff(valid_traj[:, 0])\n",
    "        lon_diff = np.diff(valid_traj[:, 1])\n",
    "        distances = np.sqrt(lat_diff**2 + lon_diff**2) * 111  # Approximate km\n",
    "        total_distance = np.sum(distances)\n",
    "        \n",
    "        # Bird distance\n",
    "        start = valid_traj[0, :2]\n",
    "        end = valid_traj[-1, :2]\n",
    "        bird_distance = np.sqrt(np.sum((end - start)**2)) * 111\n",
    "    else:\n",
    "        total_distance = 0\n",
    "        bird_distance = 0\n",
    "    \n",
    "    return {\n",
    "        'duration_min': duration_min,\n",
    "        'avg_speed_kmh': avg_speed,\n",
    "        'std_speed_kmh': std_speed,\n",
    "        'max_speed_kmh': max_speed,\n",
    "        'total_distance_km': total_distance,\n",
    "        'bird_distance_km': bird_distance,\n",
    "        'valid_points': valid_length\n",
    "    }\n",
    "\n",
    "def load_all_real_trajectories(preprocessing_dir: Path, transport_mode: str):\n",
    "    \"\"\"Load ALL real trajectories for a transport mode.\"\"\"\n",
    "    # Load interpolated trips\n",
    "    with open(preprocessing_dir / 'interpolated_trips.pkl', 'rb') as f:\n",
    "        interpolated_trips = pickle.load(f)\n",
    "    \n",
    "    # Filter by transport mode\n",
    "    mode_trips = [t for t in interpolated_trips if t['category'] == transport_mode]\n",
    "    \n",
    "    if len(mode_trips) == 0:\n",
    "        print(f\"No trips found for mode: {transport_mode}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Found {len(mode_trips)} {transport_mode} trajectories\")\n",
    "    \n",
    "    # Convert all trips\n",
    "    real_trajectories = []\n",
    "    for trip in mode_trips:\n",
    "        # GPS points: [timestamp, lat, lon, speed]\n",
    "        gps_points = trip['gps_points']\n",
    "        # Extract lat, lon, speed\n",
    "        trajectory = gps_points[:, 1:4].astype(np.float32)\n",
    "        \n",
    "        real_trajectories.append({\n",
    "            'trajectory': trajectory,\n",
    "            'trip_id': trip['trip_id'],\n",
    "            'user_id': trip['user_id'],\n",
    "            'category': trip['category'],\n",
    "            'trip_type': trip['trip_type'],\n",
    "            'original_duration': trip['duration_minutes'],\n",
    "            'length': len(trajectory),\n",
    "            'weight': trip.get('weight', 1.0)\n",
    "        })\n",
    "    \n",
    "    return real_trajectories\n",
    "\n",
    "def generate_all_matched_trajectories(\n",
    "    model,\n",
    "    scalers,\n",
    "    real_trajectories: List[Dict],\n",
    "    transport_mode: str,\n",
    "    device: str,\n",
    "    batch_size: int = 32\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Generate trajectories matching all real trajectories' lengths.\"\"\"\n",
    "    \n",
    "    # Extract lengths\n",
    "    trip_lengths = [t['length'] for t in real_trajectories]\n",
    "    \n",
    "    print(f\"\\nGenerating {len(trip_lengths)} {transport_mode} trajectories...\")\n",
    "    \n",
    "    # Generate in batches\n",
    "    gen_trajectories_norm = generate_batch_trajectories(\n",
    "        model, transport_mode, trip_lengths, batch_size, device\n",
    "    )\n",
    "    \n",
    "    # Convert to real units\n",
    "    print(\"Converting to real units...\")\n",
    "    gen_trajectories_real = inverse_transform_simple(gen_trajectories_norm, scalers)\n",
    "    \n",
    "    # Create trajectory info list\n",
    "    generated_trajectories = []\n",
    "    for i, (gen_traj, real_info) in enumerate(zip(gen_trajectories_real, real_trajectories)):\n",
    "        generated_trajectories.append({\n",
    "            'trajectory': gen_traj,\n",
    "            'matched_to': real_info['trip_id'],\n",
    "            'category': transport_mode,\n",
    "            'length': real_info['length'],\n",
    "            'weight': real_info['weight']\n",
    "        })\n",
    "    \n",
    "    return generated_trajectories\n",
    "\n",
    "def compute_aggregate_statistics(trajectories: List[Dict], label: str = \"\") -> Dict:\n",
    "    \"\"\"Compute aggregate statistics for a set of trajectories.\"\"\"\n",
    "    all_metrics = []\n",
    "    total_weight = 0\n",
    "    \n",
    "    for traj_info in trajectories:\n",
    "        metrics = compute_trajectory_metrics(\n",
    "            traj_info['trajectory'], \n",
    "            traj_info.get('length')\n",
    "        )\n",
    "        metrics['weight'] = traj_info.get('weight', 1.0)\n",
    "        all_metrics.append(metrics)\n",
    "        total_weight += metrics['weight']\n",
    "    \n",
    "    # Extract arrays for each metric\n",
    "    durations = np.array([m['duration_min'] for m in all_metrics])\n",
    "    avg_speeds = np.array([m['avg_speed_kmh'] for m in all_metrics])\n",
    "    bird_distances = np.array([m['bird_distance_km'] for m in all_metrics])\n",
    "    total_distances = np.array([m['total_distance_km'] for m in all_metrics])\n",
    "    weights = np.array([m['weight'] for m in all_metrics])\n",
    "    \n",
    "    # Compute weighted statistics\n",
    "    def weighted_mean(values, weights):\n",
    "        return np.sum(values * weights) / np.sum(weights)\n",
    "    \n",
    "    def weighted_std(values, weights):\n",
    "        mean = weighted_mean(values, weights)\n",
    "        variance = weighted_mean((values - mean)**2, weights)\n",
    "        return np.sqrt(variance)\n",
    "    \n",
    "    return {\n",
    "        'label': label,\n",
    "        'n_trajectories': len(trajectories),\n",
    "        'total_weight': total_weight,\n",
    "        'duration_mean': weighted_mean(durations, weights),\n",
    "        'duration_std': weighted_std(durations, weights),\n",
    "        'duration_min': np.min(durations),\n",
    "        'duration_max': np.max(durations),\n",
    "        'speed_mean': weighted_mean(avg_speeds, weights),\n",
    "        'speed_std': weighted_std(avg_speeds, weights),\n",
    "        'speed_min': np.min(avg_speeds),\n",
    "        'speed_max': np.max(avg_speeds),\n",
    "        'bird_distance_mean': weighted_mean(bird_distances, weights),\n",
    "        'bird_distance_std': weighted_std(bird_distances, weights),\n",
    "        'bird_distance_min': np.min(bird_distances),\n",
    "        'bird_distance_max': np.max(bird_distances),\n",
    "        'total_distance_mean': weighted_mean(total_distances, weights),\n",
    "        'total_distance_std': weighted_std(total_distances, weights),\n",
    "        'total_distance_min': np.min(total_distances),\n",
    "        'total_distance_max': np.max(total_distances),\n",
    "    }\n",
    "\n",
    "def print_mode_comparison(mode: str, real_stats: Dict, gen_stats: Dict):\n",
    "    \"\"\"Print detailed comparison for a transport mode.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{mode} COMPARISON\")\n",
    "    print('='*80)\n",
    "    \n",
    "    print(f\"\\nDataset size:\")\n",
    "    print(f\"  Real trajectories: {real_stats['n_trajectories']:,} (weight: {real_stats['total_weight']:,.0f})\")\n",
    "    print(f\"  Generated trajectories: {gen_stats['n_trajectories']:,} (weight: {gen_stats['total_weight']:,.0f})\")\n",
    "    \n",
    "    metrics = [\n",
    "        ('Duration (min)', 'duration'),\n",
    "        ('Speed avg (km/h)', 'speed'),\n",
    "        ('Bird distance (km)', 'bird_distance'),\n",
    "        ('Total distance (km)', 'total_distance')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nMetric comparison (weighted statistics):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for metric_name, metric_key in metrics:\n",
    "        real_mean = real_stats[f'{metric_key}_mean']\n",
    "        real_std = real_stats[f'{metric_key}_std']\n",
    "        gen_mean = gen_stats[f'{metric_key}_mean']\n",
    "        gen_std = gen_stats[f'{metric_key}_std']\n",
    "        \n",
    "        # Calculate relative error\n",
    "        rel_error = abs(gen_mean - real_mean) / real_mean * 100 if real_mean > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Real:      {real_mean:.2f}  {real_std:.2f} (range: [{real_stats[f'{metric_key}_min']:.2f}, {real_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Generated: {gen_mean:.2f}  {gen_std:.2f} (range: [{gen_stats[f'{metric_key}_min']:.2f}, {gen_stats[f'{metric_key}_max']:.2f}])\")\n",
    "        print(f\"  Relative Error: {rel_error:.1f}%\")\n",
    "\n",
    "def create_sample_visualization_map(\n",
    "    real_trajectories: List[Dict],\n",
    "    generated_trajectories: List[Dict],\n",
    "    mode: str,\n",
    "    n_samples: int = 10,\n",
    "    output_file: str = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"Create a map with a sample of trajectories for visualization.\"\"\"\n",
    "    # Sample trajectories if needed\n",
    "    if len(real_trajectories) > n_samples:\n",
    "        sample_indices = np.random.choice(len(real_trajectories), n_samples, replace=False)\n",
    "        real_sample = [real_trajectories[i] for i in sample_indices]\n",
    "        gen_sample = [generated_trajectories[i] for i in sample_indices]\n",
    "    else:\n",
    "        real_sample = real_trajectories\n",
    "        gen_sample = generated_trajectories\n",
    "    \n",
    "    # Prepare for visualization\n",
    "    all_trajectories = []\n",
    "    labels = []\n",
    "    types = []\n",
    "    \n",
    "    for i, traj_info in enumerate(real_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Real {mode} {i+1}\")\n",
    "        types.append('real')\n",
    "    \n",
    "    for i, traj_info in enumerate(gen_sample):\n",
    "        all_trajectories.append(traj_info['trajectory'])\n",
    "        labels.append(f\"Generated {mode} {i+1}\")\n",
    "        types.append('generated')\n",
    "    \n",
    "    # Calculate center\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    for traj in all_trajectories:\n",
    "        valid_mask = ~np.all(traj == 0, axis=1)\n",
    "        all_lats.extend(traj[valid_mask, 0])\n",
    "        all_lons.extend(traj[valid_mask, 1])\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=11)\n",
    "    \n",
    "    # Define colors\n",
    "    real_colors = ['blue', 'darkblue', 'lightblue', 'navy', 'steelblue']\n",
    "    generated_colors = ['red', 'darkred', 'orange', 'pink', 'coral']\n",
    "    \n",
    "    # Add trajectories\n",
    "    for i, (traj, label, traj_type) in enumerate(zip(all_trajectories, labels, types)):\n",
    "        if traj_type == 'real':\n",
    "            color = real_colors[i % len(real_colors)]\n",
    "            line_style = None\n",
    "        else:\n",
    "            color = generated_colors[(i - len(real_sample)) % len(generated_colors)]\n",
    "            line_style = '10'\n",
    "        \n",
    "        # Get valid points\n",
    "        if traj_type == 'generated':\n",
    "            traj_info = gen_sample[i - len(real_sample)]\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "        else:\n",
    "            valid_mask = ~np.all(traj == 0, axis=1)\n",
    "            valid_traj = traj[valid_mask]\n",
    "        \n",
    "        points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "        \n",
    "        # Add polyline\n",
    "        if line_style:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.7,\n",
    "                dash_array=line_style,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "        else:\n",
    "            folium.PolyLine(\n",
    "                points,\n",
    "                color=color,\n",
    "                weight=3,\n",
    "                opacity=0.8,\n",
    "                popup=label\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 50px; right: 50px; width: 250px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 10px\">\n",
    "    <p style=\"margin: 0;\"><b>{mode} Trajectories</b></p>\n",
    "    <p style=\"margin: 5px 0;\">Sample size: {len(real_sample)} of {len(real_trajectories)} total</p>\n",
    "    <p style=\"margin: 10px 0 5px 0;\"><b>Line styles:</b></p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: blue;\"></span> Real trajectories</p>\n",
    "    <p style=\"margin: 5px 0;\"><span style=\"color: red;\"></span> Generated trajectories</p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    if output_file:\n",
    "        m.save(output_file)\n",
    "        print(f\"Sample visualization saved to: {output_file}\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def create_all_generated_trajectories_map(\n",
    "    all_generated_trajectories: Dict[str, List[Dict]],\n",
    "    output_file: str = \"all_generated_trajectories_old.html\",\n",
    "    max_trajectories_per_mode: int = None\n",
    ") -> folium.Map:\n",
    "    \"\"\"\n",
    "    Create a map with ALL generated trajectories, colored by transport type.\n",
    "    \n",
    "    Args:\n",
    "        all_generated_trajectories: Dict with transport mode as key and list of trajectory dicts as value\n",
    "        output_file: Path to save the HTML file\n",
    "        max_trajectories_per_mode: Optional limit on trajectories per mode (for performance)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define colors for each transport mode\n",
    "    mode_colors = {\n",
    "        'CAR': '#FF0000',        # Red\n",
    "        'WALKING': '#00FF00',    # Green\n",
    "        'BIKE': '#0000FF',       # Blue\n",
    "        'PUBLIC_TRANSPORT': '#FF00FF',  # Magenta\n",
    "        'MIXED': '#FFA500'       # Orange\n",
    "    }\n",
    "    \n",
    "    # Collect all trajectories with their modes\n",
    "    all_trajectories = []\n",
    "    all_lats = []\n",
    "    all_lons = []\n",
    "    \n",
    "    total_trajectories = 0\n",
    "    for mode, trajectories in all_generated_trajectories.items():\n",
    "        if len(trajectories) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Limit trajectories per mode if specified\n",
    "        mode_trajectories = trajectories\n",
    "        if max_trajectories_per_mode and len(trajectories) > max_trajectories_per_mode:\n",
    "            sample_indices = np.random.choice(len(trajectories), max_trajectories_per_mode, replace=False)\n",
    "            mode_trajectories = [trajectories[i] for i in sample_indices]\n",
    "        \n",
    "        for i, traj_info in enumerate(mode_trajectories):\n",
    "            traj = traj_info['trajectory']\n",
    "            valid_length = traj_info['length']\n",
    "            valid_traj = traj[:valid_length]\n",
    "            \n",
    "            # Extract coordinates\n",
    "            points = [(lat, lon) for lat, lon in valid_traj[:, :2]]\n",
    "            if len(points) > 1:  # Only add trajectories with more than 1 point\n",
    "                all_trajectories.append({\n",
    "                    'points': points,\n",
    "                    'mode': mode,\n",
    "                    'color': mode_colors.get(mode, '#808080'),  # Default to gray\n",
    "                    'label': f\"{mode} Trajectory {total_trajectories + 1}\"\n",
    "                })\n",
    "                \n",
    "                # Collect coordinates for centering\n",
    "                lats, lons = zip(*points)\n",
    "                all_lats.extend(lats)\n",
    "                all_lons.extend(lons)\n",
    "                total_trajectories += 1\n",
    "    \n",
    "    print(f\"Creating map with {total_trajectories} generated trajectories\")\n",
    "    \n",
    "    if not all_trajectories:\n",
    "        print(\"No valid trajectories found!\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate center\n",
    "    center = (np.mean(all_lats), np.mean(all_lons))\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=center, zoom_start=10)\n",
    "    \n",
    "    # Add trajectories\n",
    "    for traj_data in all_trajectories:\n",
    "        folium.PolyLine(\n",
    "            traj_data['points'],\n",
    "            color=traj_data['color'],\n",
    "            weight=2,\n",
    "            opacity=0.7,\n",
    "            popup=traj_data['label']\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Create legend\n",
    "    legend_items = []\n",
    "    mode_counts = {}\n",
    "    for mode, trajectories in all_generated_trajectories.items():\n",
    "        if len(trajectories) > 0:\n",
    "            actual_count = len(trajectories)\n",
    "            displayed_count = min(actual_count, max_trajectories_per_mode) if max_trajectories_per_mode else actual_count\n",
    "            mode_counts[mode] = (displayed_count, actual_count)\n",
    "            color = mode_colors.get(mode, '#808080')\n",
    "            legend_items.append(f'<span style=\"color: {color};\"></span> {mode}: {displayed_count:,} trajectories')\n",
    "            if max_trajectories_per_mode and actual_count > max_trajectories_per_mode:\n",
    "                legend_items[-1] += f' (of {actual_count:,} total)'\n",
    "    \n",
    "    legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                top: 20px; right: 20px; width: 300px; height: auto;\n",
    "                background-color: white; border:2px solid grey; z-index:9999; \n",
    "                font-size:14px; padding: 15px; border-radius: 5px;\">\n",
    "    <h4 style=\"margin: 0 0 10px 0;\">Generated Trajectories by Transport Mode</h4>\n",
    "    <p style=\"margin: 5px 0;\"><b>Total displayed: {total_trajectories:,} trajectories</b></p>\n",
    "    {'<br>'.join(legend_items)}\n",
    "    <p style=\"margin: 10px 0 0 0; font-size: 12px; color: #666;\">\n",
    "    Click on any trajectory line for details\n",
    "    </p>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # Save map\n",
    "    m.save(output_file)\n",
    "    print(f\"All generated trajectories visualization saved to: {output_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nVisualization Summary:\")\n",
    "    for mode, (displayed, total) in mode_counts.items():\n",
    "        print(f\"  {mode}: {displayed:,} trajectories displayed (of {total:,} total)\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "def run_complete_analysis(\n",
    "    checkpoint_dir: Path,\n",
    "    preprocessing_dir: Path,\n",
    "    transport_modes: List[str] = [\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "    batch_size: int = 32,\n",
    "    save_sample_maps: bool = True,\n",
    "    sample_size: int = 10,\n",
    "    create_all_trajectories_map: bool = True,\n",
    "    max_trajectories_per_mode: int = 500  # Limit for performance\n",
    "):\n",
    "    \"\"\"Run complete analysis generating trajectories for ALL real trajectories.\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    device = get_device()\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading model...\")\n",
    "    model, config = load_model_simple(checkpoint_dir, device)\n",
    "    \n",
    "    # Load scalers\n",
    "    print(\"Loading scalers...\")\n",
    "    scalers = load_scaler_simple(preprocessing_dir)\n",
    "    \n",
    "    # Storage for results\n",
    "    all_results = []\n",
    "    all_generated_trajectories = {}\n",
    "    \n",
    "    # Process each transport mode\n",
    "    for mode in transport_modes:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing {mode}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        # Load ALL real trajectories for this mode\n",
    "        real_trajectories = load_all_real_trajectories(preprocessing_dir, mode)\n",
    "        \n",
    "        if len(real_trajectories) == 0:\n",
    "            print(f\"Skipping {mode} - no trajectories found\")\n",
    "            continue\n",
    "        \n",
    "        # Generate matched trajectories for ALL real ones\n",
    "        generated_trajectories = generate_all_matched_trajectories(\n",
    "            model, scalers, real_trajectories, mode, device, batch_size\n",
    "        )\n",
    "        \n",
    "        # Store generated trajectories for the combined map\n",
    "        all_generated_trajectories[mode] = generated_trajectories\n",
    "        \n",
    "        # Compute aggregate statistics\n",
    "        print(\"\\nComputing statistics...\")\n",
    "        real_stats = compute_aggregate_statistics(real_trajectories, f\"Real {mode}\")\n",
    "        gen_stats = compute_aggregate_statistics(generated_trajectories, f\"Generated {mode}\")\n",
    "        \n",
    "        # Print comparison\n",
    "        print_mode_comparison(mode, real_stats, gen_stats)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'mode': mode,\n",
    "            'real_stats': real_stats,\n",
    "            'gen_stats': gen_stats,\n",
    "            'n_trajectories': len(real_trajectories)\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Create sample visualization if requested\n",
    "        if save_sample_maps:\n",
    "            create_sample_visualization_map(\n",
    "                real_trajectories,\n",
    "                generated_trajectories,\n",
    "                mode,\n",
    "                n_samples=sample_size,\n",
    "                output_file=f\"{mode.lower()}_sample_trajectories.html\"\n",
    "            )\n",
    "    \n",
    "    # Create map with ALL generated trajectories\n",
    "    if create_all_trajectories_map and all_generated_trajectories:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"Creating combined map with all generated trajectories...\")\n",
    "        print('='*80)\n",
    "        \n",
    "        create_all_generated_trajectories_map(\n",
    "            all_generated_trajectories,\n",
    "            output_file=\"all_generated_trajectories_old.html\",\n",
    "            max_trajectories_per_mode=max_trajectories_per_mode\n",
    "        )\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY ACROSS ALL MODES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    summary_data = []\n",
    "    for result in all_results:\n",
    "        mode = result['mode']\n",
    "        real_stats = result['real_stats']\n",
    "        gen_stats = result['gen_stats']\n",
    "        \n",
    "        for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "            summary_data.append({\n",
    "                'transport_mode': mode,\n",
    "                'metric': metric,\n",
    "                'real_mean': real_stats[f'{metric}_mean'],\n",
    "                'real_std': real_stats[f'{metric}_std'],\n",
    "                'generated_mean': gen_stats[f'{metric}_mean'],\n",
    "                'generated_std': gen_stats[f'{metric}_std'],\n",
    "                'n_samples': result['n_trajectories'],\n",
    "                'relative_error': abs(gen_stats[f'{metric}_mean'] - real_stats[f'{metric}_mean']) / real_stats[f'{metric}_mean'] * 100 if real_stats[f'{metric}_mean'] > 0 else 0\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('all_trajectories_comparison.csv', index=False)\n",
    "    print(f\"\\nComplete comparison saved to: all_trajectories_comparison.csv\")\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\nOverall Performance Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    metric_names = {\n",
    "        'duration': 'Duration (min)',\n",
    "        'speed': 'Speed (km/h)',\n",
    "        'bird_distance': 'Bird Distance (km)',\n",
    "        'total_distance': 'Total Distance (km)'\n",
    "    }\n",
    "    \n",
    "    for metric in ['duration', 'speed', 'bird_distance', 'total_distance']:\n",
    "        metric_data = summary_df[summary_df['metric'] == metric]\n",
    "        avg_error = metric_data['relative_error'].mean()\n",
    "        print(f\"{metric_names[metric]}: Average relative error = {avg_error:.1f}%\")\n",
    "    \n",
    "    return summary_df, all_results, all_generated_trajectories\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    checkpoint_dir = Path(\"../results/optimal_medium_v2\")\n",
    "    preprocessing_dir = Path(\"../data/processed\")\n",
    "    \n",
    "    # Run complete analysis for ALL trajectories\n",
    "    summary_df, results, all_generated = run_complete_analysis(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        preprocessing_dir=preprocessing_dir,\n",
    "        transport_modes=[\"CAR\", \"WALKING\", \"MIXED\", \"BIKE\", \"PUBLIC_TRANSPORT\"],\n",
    "        batch_size=32,  # Process in batches for efficiency\n",
    "        save_sample_maps=True,  # Save sample visualizations\n",
    "        sample_size=10,  # Number of trajectories to show in sample maps\n",
    "        create_all_trajectories_map=True,  # Create the new combined map\n",
    "        max_trajectories_per_mode=500  # Limit trajectories per mode for performance\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825e983-bb72-4036-8319-bb1a1f59b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a58343-bc60-4145-87db-ba4dabb1cc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e359e-8378-408d-82b3-704dc9e21845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6d9c7-c5bd-4323-816f-2713d3fee56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421f047-55db-4152-88ac-0b52cd270c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23198c-6546-42d1-ba0a-432b85d8a22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436f162-3177-4950-932c-da16719c22a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86cda37-3991-425f-acab-ec699e819bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e3c04-c2b3-46a0-9d45-455566cb56d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
